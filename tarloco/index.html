<!-- Styling -->
<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <style>
    body {
      max-width: 1200px;
      margin: auto;
      padding: 20px;
    }
    .hero-body, .section {
      padding-left: 2rem;
      padding-right: 2rem;
    }
    img {
      display: block;
      margin-left: auto;
      margin-right: auto;
      max-width: 90%;
      height: auto;
    }
    video {
      max-width: 100%;
      height: auto;
    }
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<style>
  .publication-links .external-link {
    color: rgb(255, 255, 255) !important;
  }
</style>

<!-- Title and headers -->
<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion</h1>
            <div class="subtitle is-4">Improving Sim-to-Real Generalization through Contrastive Learning</div>
            <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block"></span>
                <a href="https://www.amrmousa.com" target="_blank">Amr Mousa</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a target="_blank">Neil Karavis</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="https://michelecaprio.wixsite.com/caprio" target="_blank">Michele Caprio</a><sup>1</sup>,</span>
                <span class="author-block"></span>
                  <a href="https://panweihit.github.io/" target="_blank">Wei Pan</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://personalpages.manchester.ac.uk/staff/Richard.Allmendinger/" target="_blank">Richard Allmendinger</a><sup>1</sup>
                </span>
                </span>

                <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <strong>Affiliations:</strong><br>
                  <sup>1</sup> University of Manchester, Manchester, United Kingdom<br>
                  <sup>2</sup> BAE Systems, United Kingdom<br>
                </span>
                <br>
                <span class="author-block">
                  <strong>Conference:</strong><br> <a href="https://iros25.org" target="_blank">IROS 2025</a> (Accepted)
                </span>
                <br>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2503.20839" target="_blank"
                  class="external-link button is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ammousa/tarloco" target="_blank"
                    class="external-link button is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2503.20839" target="_blank"
                  class="external-link button is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                    <span>arXiv</span>
                  </a>
                  </span>

                  <!-- WandB Results Link -->
                  <span class="link-block">
                  <a href="https://wandb.ai/amrmousa-m/TAR_workspace/" target="_blank"
                  class="external-link button is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-chart-line"></i>
                  </span>
                  <span>Results</span>
                  </a>
                  </span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Video  -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- <h2 class="title is-3">Video Presentation</h2> -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <div class="publication-video">
            <div class="video-container">
              <iframe width="100%" height="500" 
                      src="https://www.youtube.com/embed/ckKD85L1dV8" 
                      title="YouTube video player" frameborder="0" 
                      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
                      allowfullscreen>
              </iframe>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End Video Presentation -->


<!--  abstract -->
<section class="hero is-small is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <div style="margin: 3rem 0; opacity: 0;"></div>
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Quadrupedal locomotion via reinforcement learning (RL) is commonly addressed using the teacher-student paradigm, where a privileged teacher guides a proprioceptive student policy. However, key challenges such as representation misalignment between privileged teacher and proprioceptive-only student, covariate shift due to behavioral cloning, and lack of deployable adaption; lead to poor generalization in real-world scenarios.
            We propose Teacher-Aligned Representations via Contrastive Learning (TAR), a framework that leverages privileged information with self-supervised contrastive learning to bridge this gap.
            By distilling from a privileged teacher in simulation and constructing structured latent spaces through contrastive objectives, our student policy surpasses the fully privileged ‚ÄúTeacher‚Äù and exhibits robust generalization to out-of-distribution (OOD) scenarios.
            Results showed accelerated training by 2√ó compared to state-of-the-art baselines to achieve peak performance. OOD scenarios showed better generalization by 40% on average compared to existing methods.
            Additionally, TAR transitions seamlessly into learning during deployment without requiring privileged states, setting a new benchmark in sample-efficient, adaptive locomotion and enabling continual fine-tuning in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
  </div>
  </div>
  </div>
  </div>
  <div style="margin: 2rem 0; opacity: 0;"></div>
</section>
<!-- End abstract -->


<!-- Technical Concept Section -->
<section class="section hero">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Technical Concept</h2>
        <div style="margin: 2rem 0; opacity: 0;"></div>
        <!-- <p class="subtitle is-5 has-text-grey">
          Contrastive Learning for Representation Alignment in Quadrupedal Locomotion
        </p> -->
        <figure class="image is-16by9">
          <img src="static/images/fig-go1_go2_sim.png" alt="Simulation of Go1 and Go2 robots">
        </figure>
        <div class="content has-text-justified mt-4">
          <p>
            The core idea of this work is to <strong>leverage contrastive learning</strong> for aligning latent representations between a <em>privileged teacher</em> and a <em>proprioceptive student</em> within a reinforcement learning framework for quadrupedal locomotion. This approach addresses challenges in generalization and sim-to-real transfer by enforcing structured latent space alignment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Training Framework Architecture -->
<section class="section hero">
  <div class="container">
    <h3 class="title is-5 has-text-centered">Training Framework Overview</h3>
    <figure class="image" style="width: 70%; margin: auto;">
      <img src="static/images/arch_full_1.png" alt="Training Framework Architecture">
    </figure>
    <div class="content has-text-justified" style="max-width: 65%; margin: 2rem auto 0 auto;">
      <p>
        Our training pipeline integrates a <strong>teacher encoder</strong> that processes privileged states (<code>S</code>) to produce structured latent vectors (<code>Z<sup>T</sup></code>). The <strong>student encoder</strong> extracts features (<code>Z<sup>S</sup></code>) from proprioceptive inputs (<code>O<sub>t</sub></code>) and hidden states (<code>h<sub>t-1</sub></code>). 
      </p>
      <p>
        A <strong>triplet loss</strong> aligns the student's next-state prediction (<code>&#x3C9;<sub>t+1</sub><sup>+</sup></code>) close to the teacher's future encoding (<code>Z<sub>t+1</sub></code>), while pushing it away from negative samples (<code>Z<sub>t+1</sub><sup>-</sup></code>) drawn from other contexts.
      </p>
      <p>
        The <strong>actor</strong> and <strong>critic</strong> are optimized via policy gradients, with the critic additionally refined by the triplet loss. A <strong>velocity estimator</strong> is trained via regression and frozen post-training to enhance deployment robustness.
      </p>
    </div>
  </div>
</section>

<!-- Fine-Tuning and Adaptation -->
<section class="section hero">
  <div class="container">
    <h3 class="title is-5 has-text-centered">Privileged-Free Fine-Tuning & Adaptation</h3>
    <figure class="image" style="width: 70%; margin: auto;">
      <img src="static/images/arch_ft_1.png" alt="Fine-Tuning Framework">
    </figure>
    <div class="content has-text-justified" style="max-width: 65%; margin: 2rem auto 0 auto;">
      <p>
        During <strong>adaptation</strong> or <strong>privileged-free learning</strong>, the teacher encoder is removed. The student autonomously constructs positive and negative pairs using its own proprioceptive observations (<code>O<sub>t+1</sub></code>) and those from other agents (<code>O<sub>t+1</sub><sup>j &ne; i</sup></code>), along with their hidden states.
      </p>
      <p>
        This <strong>self-supervised contrastive sampling</strong> enforces temporal consistency, enabling the student to learn robust latent representations without external supervision.
      </p>
      <p>
        The design is inherently <strong>off-policy compatible</strong>, supporting efficient fine-tuning in <em>dynamic</em> and <em>non-stationary environments</em>.
      </p>
    </div>
  </div>
</section>



<!-- Video grid -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Simulation Results</h2>
      <div class="columns is-multiline is-centered">

        <!-- Row 1 Title -->
        <div class="column is-full">
          <h3 class="title is-4 has-text-centered">üòé In-distribution cases</h3>
        </div>
        <div class="columns is-centered">
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: green; margin-bottom: 5px;">OURS</h3>
            <video poster="" id="video-ood-1" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/id/m0_f0.1_s1.0_7.5k_ours.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: rgb(0, 81, 255); margin-bottom: 5px;">HIM</h3>
            <video poster="" id="video-ood-2" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/id/m0_f0.1_s1.0_7.5k_him.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: rgb(0, 0, 0); margin-bottom: 5px;">SLR</h3>
            <video poster="" id="video-ood-3" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/id/m0_f0.1_s1.0_7.5k_slr.mp4" type="video/mp4">
            </video>
          </div>
        </div>
        <!-- Row 2 Title -->
        <div class="column is-full">
          <h3 class="title is-4 has-text-centered">üò≥ Out-of-distribution cases</h3>
        </div>
        <div class="columns is-centered">
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: green; margin-bottom: 5px;">OURS</h3>
            <video poster="" id="video-ood-1" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/ood/m0_f1.0_s2.0_20k_ours.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: rgb(0, 81, 255); margin-bottom: 5px;">HIM</h3>
            <video poster="" id="video-ood-2" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/ood/m0_f1.0_s2.0_20k_slr.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column is-one-third">
            <h3 class="title is-6 has-text-centered" style="color: rgb(0, 0, 0); margin-bottom: 5px;">SLR</h3>
            <video poster="" id="video-ood-3" autoplay controls muted loop width="100%">
              <source src="static/videos/testing/ood/m0_f1.0_s2.0_20k_slr.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @misc{mousa2025tar,
      title = {TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion},
      author = {Mousa, Amr and Karavis, Neil and Caprio, Michele and Pan, Wei and Allmendinger, Richard},
      year = {2025},
      url = {https://arxiv.org/abs/2503.20839},
      note = {Submitted to IROS 2025 (Pending Decision)}
    }
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>, adapted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page. Feel free to reuse the source code, but please include a link back to this page in the footer. <br> This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
