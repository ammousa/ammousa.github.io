<!doctype html><!-- This site was created with Hugo Blox. https://hugoblox.com --><!-- Last Published: August 22, 2025 --><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Hugo Blox Builder 5.9.7"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><script src=/js/mathjax-config.js></script><link rel=stylesheet href=/css/vendor-bundle.min.26c458e6907dc03073573976b7f4044e.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1.9.4/css/academicons.min.css integrity="sha512-IW0nhlW5MgNydsXJO40En2EoCkTTjZhI3yuODrZIc8cQ4h1XcF53PsqDHa09NqnkXuIe0Oiyyj171BqZFwISBw==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script><link rel=stylesheet href=/css/wowchemy.5691485ce8e88de823038b8e3d90ec13.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><meta name=description content="T A R L o c o üêæ Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion üìÑ Paper üßæ arXiv üíª Code üìä W&B Results Amr Mousa1, Neil Karavis2, Michele Caprio1, Wei Pan1, Richard Allmendinger1 1 University of Manchester, UK &nbsp; | &nbsp; 2 BAE Systems, UK Conference: IROS 2025 (Accepted) üì¢ News 2025‚Äë08‚Äë18 ‚Äî Project website goes live with videos and results."><link rel=alternate hreflang=en-us href=https://amrmousa.com/tarloco/><link rel=canonical href=https://amrmousa.com/tarloco/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu1b3412e5c2d60ae0a142be2ebea86b0e_21193_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu1b3412e5c2d60ae0a142be2ebea86b0e_21193_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@GetResearchDev"><meta property="twitter:creator" content="@GetResearchDev"><meta property="twitter:image" content="https://amrmousa.com/media/icon_hu1b3412e5c2d60ae0a142be2ebea86b0e_21193_512x512_fill_lanczos_center_3.png"><meta property="og:type" content="website"><meta property="og:site_name" content="Amr Mousa"><meta property="og:url" content="https://amrmousa.com/tarloco/"><meta property="og:title" content="Amr Mousa"><meta property="og:description" content="T A R L o c o üêæ Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion üìÑ Paper üßæ arXiv üíª Code üìä W&B Results Amr Mousa1, Neil Karavis2, Michele Caprio1, Wei Pan1, Richard Allmendinger1 1 University of Manchester, UK &nbsp; | &nbsp; 2 BAE Systems, UK Conference: IROS 2025 (Accepted) üì¢ News 2025‚Äë08‚Äë18 ‚Äî Project website goes live with videos and results."><meta property="og:image" content="https://amrmousa.com/media/icon_hu1b3412e5c2d60ae0a142be2ebea86b0e_21193_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><title>Amr Mousa</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=13ca20e0f4824eb2d93c0c2b21e2b455><script src=/js/wowchemy-init.min.9e4214442a7711d35691acd58f6f6361.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Amr Mousa</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Amr Mousa</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>About Me</span></a></li><li class=nav-item><a class=nav-link href=/#news><span>News</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#experience><span>Experience</span></a></li><li class=nav-item><a class=nav-link href=/#honors><span>Honors</span></a></li><li class=nav-item><a class=nav-link href=/#certificates><span>Certificates</span></a></li><li class=nav-item><a class=nav-link href=/#gallery><span>Gallery</span></a></li><li class=nav-item><a class=nav-link href=/#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><article class=article><div class="article-container pt-3"><h1></h1><div class=article-metadata></div></div><div class=article-container><div class=article-style><style>.link-cards{display:grid;grid-template-columns:repeat(auto-fit,minmax(150px,1fr));gap:1rem;margin:2rem auto;max-width:1000px}.link-card{display:flex;align-items:center;gap:18px;padding:.01rem 1rem;border-radius:12px;text-decoration:none;color:inherit;background:linear-gradient(135deg,#0b517c 0%,#4d9cac 100%);color:#fff;box-shadow:0 8px 25px rgba(0,0,0,8%);transition:transform .2s ease,box-shadow .2s ease}.link-card:hover{transform:translateY(-4px);box-shadow:0 16px 35px rgba(0,0,0,.15);color:#fce6b7}.link-card .icon{font-size:1.6rem}.link-card .text{display:flex;flex-direction:column;font-family:inter,helvetica neue,Arial,sans-serif}.link-card .title{font-size:.75rem;font-weight:500}.link-card .desc{font-size:.5rem;opacity:.75}.hero-metrics{display:grid;grid-template-columns:repeat(auto-fit,minmax(160px,1fr));gap:1rem;margin:1rem 0}.metric-card{background:linear-gradient(135deg,#0b517c 0%,#4d9cac 100%);color:#fff;padding:1rem;border-radius:15px;text-align:center;transform:translateY(0);transition:all .3s ease;box-shadow:0 10px 30px rgba(0,0,0,.1)}.metric-card:hover{transform:translateY(-10px);box-shadow:0 20px 40px rgba(0,0,0,.2)}.metric-number{font-size:2rem;font-weight:700;display:block;margin-bottom:.5rem}.metric-label{font-size:.8rem;opacity:.9}.interactive-tabs{display:flex;border-bottom:2px solid #0b517c;margin-bottom:2rem}.tab-button{padding:1rem 2rem;background:0 0;border:none;cursor:pointer;font-size:1.1rem;font-weight:500;color:#666;transition:all .3s ease;border-bottom:3px solid transparent}.tab-button.active{color:#0b517c;border-bottom-color:#0b517c}.tab-button:hover{color:#000;background:#f0f4fa}.highlight-box{background:linear-gradient(135deg,#fff,#fce6b7);padding:1.5rem;border-radius:10px;margin:1rem 0;border-left:5px solid #e17055}@media(max-width:768px){.hero-metrics{grid-template-columns:1fr}.comparison-grid{grid-template-columns:1fr}.interactive-tabs{flex-direction:column}}</style><div style=text-align:center><h1>T A R L o c o</h1></div><p><figure><div class="d-flex justify-content-center"><div class=w-100><img alt="TARLoco Index Image" srcset="/tarloco/images/index_hu1f909f6c9e78d26c4d607a96b35ec022_935786_b33927df22e8daea7414d2cd6ed13df0.webp 400w,
/tarloco/images/index_hu1f909f6c9e78d26c4d607a96b35ec022_935786_e45f4869067d5aa54201054171a60181.webp 760w,
/tarloco/images/index_hu1f909f6c9e78d26c4d607a96b35ec022_935786_1200x1200_fit_q75_h2_lanczos.webp 1200w" src=/tarloco/images/index_hu1f909f6c9e78d26c4d607a96b35ec022_935786_b33927df22e8daea7414d2cd6ed13df0.webp width=760 height=279 loading=lazy data-zoomable></div></div></figure></p><div style=text-align:center><h3>üêæ Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion</h3></div><div class=link-cards><a class="link-card paper" href=https://arxiv.org/pdf/2503.20839 target=_blank rel="noopener noreferrer"><span class=icon>üìÑ</span>
<span class=text><span class=title>Paper</span>
<!-- <span class="desc">Read the full manuscript</span> --></span></a><a class="link-card arxiv" href=https://arxiv.org/abs/2503.20839 target=_blank rel="noopener noreferrer"><span class=icon>üßæ</span>
<span class=text><span class=title>arXiv</span>
<!-- <span class="desc">Abstract & citation details</span> --></span></a><a class="link-card code" href=https://github.com/ammousa/TARLoco target=_blank rel="noopener noreferrer"><span class=icon>üíª</span>
<span class=text><span class=title>Code</span>
<!-- <span class="desc">GitHub repository</span> --></span></a><a class="link-card result" href=https://wandb.ai/amrmousa-m/TAR_workspace/ target=_blank rel="noopener noreferrer"><span class=icon>üìä</span>
<span class=text><span class=title>W&B Results</span><!-- <span class="desc">W&B dashboard</span> --></span></a></div><!-- --------------------------------- --><div style="text-align:center;margin:2rem 0"><div style="font-size:1rem;margin:.5rem 0;text-align:center"><p><a href=https://amrmousa.com>Amr Mousa</a><sup>1</sup>, Neil Karavis<sup>2</sup>,
<a href=https://michelecaprio.wixsite.com/caprio>Michele Caprio</a><sup>1</sup>,
<a href=https://panweihit.github.io/>Wei Pan</a><sup>1</sup>,
<a href=https://personalpages.manchester.ac.uk/staff/richard.allmendinger/default.htm>Richard Allmendinger</a><sup>1</sup></p><p style=font-size:.9rem;color:#666;margin:0><sup>1</sup> University of Manchester, UK &nbsp; | &nbsp;
<sup>2</sup> BAE Systems, UK<br><strong>Conference:</strong>
<a href=https://www.iros2025.org/>IROS 2025</a> (Accepted)</p></div></div><h2 id=-news>üì¢ News</h2><ul><li><strong>2025‚Äë08‚Äë18</strong> ‚Äî Project website goes live with videos and results.</li><li><strong>2025‚Äë06‚Äë15</strong> ‚Äî Accepted at <strong>IROS 2025</strong>.</li></ul><hr></br><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/ckKD85L1dV8?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><h2 id=-abstract>üìå Abstract</h2><p>Quadrupedal locomotion via reinforcement learning (RL) is commonly addressed using the teacher‚Äìstudent paradigm, where a privileged teacher guides a proprioceptive student policy. However, key challenges such as <strong>representation misalignment</strong> between privileged teacher and proprioceptive‚Äëonly student, <strong>covariate shift</strong> due to behavioral cloning, and <strong>lack of deployable adaptation</strong> lead to poor generalization in real‚Äëworld scenarios. We propose <strong>Teacher‚ÄëAligned Representations via Contrastive Learning (TAR)</strong>, a framework that leverages privileged information with <strong>self‚Äësupervised contrastive learning</strong> to bridge this gap. By distilling from a privileged teacher in simulation and constructing structured latent spaces through contrastive objectives, our student policy <strong>surpasses</strong> the fully privileged ‚ÄúTeacher‚Äù and exhibits <strong>robust generalization</strong> to out‚Äëof‚Äëdistribution (OOD) scenarios. Results showed <strong>2√ó faster training</strong> to reach peak performance compared to state‚Äëof‚Äëthe‚Äëart baselines, and <strong>~40%</strong> better OOD generalization on average. Additionally, TAR transitions seamlessly into <strong>privileged‚Äëfree fine‚Äëtuning</strong> during deployment, enabling continual adaptation in the real world.</p><div class=hero-metrics><div class=metric-card><span class=metric-number>3√ó</span>
<span class=metric-label>Faster Convergence</span></div><div class=metric-card><span class=metric-number>7,500</span>
<span class=metric-label>Iterations to Peak</span></div><div class=metric-card><span class=metric-number>+61%</span>
<span class=metric-label>Return vs Baselines</span></div><div class=metric-card><span class=metric-number>103%</span>
<span class=metric-label>Return vs Teacher</span></div></div></br><hr><div class=interactive-tabs><button class="tab-button active" onclick='showTab("training",event)'>Training</button>
<button class=tab-button onclick='showTab("finetuning",event)'>Fine-tuning</button>
<button class=tab-button onclick='showTab("results",event)'>Results</button></div><div id=training class=tab-content><h2 id=-training-framework-overview>‚öôÔ∏è Training Framework Overview</h2><p>The core idea of our method is to leverages <strong>contrastive learning</strong> to align latent representations between a <em>privileged teacher</em> and a <em>proprioceptive student</em> within RL paradigm. By structuring a shared latent space, the student utilizes the teacher&rsquo;s privileged signals during training, enabling improved <strong>generalization</strong> and <strong>sim2real transfer</strong>. At deployment, the student operates with <strong>proprioception only</strong>, maintaining robust performance in diverse and dynamic environments.</p><img src=images/arch.gif alt="TAR Training Architecture" style=max-width:100%;height:auto;border-radius:10px><p><strong>Pipeline summary</strong></p><ul><li><strong>Teacher encoder</strong> consumes privileged states $S_t$ to produce structured embeddings $Z^{T}_t$.</li><li><strong>Student encoder</strong> consumes proprioceptive inputs $O_t$ and hidden state $h_{t-1}$ to produce $Z^{S}_t$.</li><li><strong>Contrastive alignment (triplet loss):</strong> the student&rsquo;s next-state prediction
$\tilde{Z}^{+}_{t+1}$ is pulled <strong>towards</strong> the teacher&rsquo;s future code
$Z_{t+1}$ and <strong>away</strong> from negatives
$Z^{-}_{t+1}$ sampled from other contexts.</li><li><strong>Policy optimization:</strong> actor‚Äìcritic is trained with policy gradients; the critic additionally leverages the contrastive signal for representation shaping.</li><li><strong>Velocity estimator:</strong> trained via regression and <strong>frozen</strong> post-training to stabilize deployment.</li></ul><p><strong>Design goals</strong></p><ul><li>Robust latent structure that transfers to diverse terrains and dynamics.</li><li>Student policy that remains <strong>privileged-free</strong> at test time without performance collapse.</li></ul></div><!-- --------------- --><div id=finetuning class=tab-content style=display:none><h2 id=privileged-free-fine-tuning--adaptation>Privileged-Free Fine-Tuning & Adaptation</h2><figure id=figure-self-supervised-adaptation-without-access-to-the-teacher><div class="d-flex justify-content-center"><div class=w-100><img alt="Privileged-Free Fine-Tuning" src=/tarloco/images/arch_ft.gif loading=lazy data-zoomable></div></div><figcaption>Self-supervised adaptation without access to the teacher.</figcaption></figure><p>During <strong>adaptation</strong> (or privileged-free learning), the teacher encoder is removed:</p><ul><li>The student forms <strong>positive/negative pairs</strong> from its own proprioceptive rollouts:<ul><li>Positives from temporally adjacent observations $O_{t+1}$ with consistent hidden state context.</li><li>Negatives from other agents or distant contexts $O^{j\neq i}_{t+1}$.</li></ul></li><li>This <strong>self-supervised contrastive sampling</strong> enforces temporal consistency and context separation <strong>without external supervision</strong>.</li><li>The method is <strong>off-policy compatible</strong>, enabling efficient fine-tuning in <strong>dynamic, non-stationary</strong> environments.</li></ul></div><!-- --------------- --><div id=results class=tab-content style=display:none><h2 id=-results>üìà Results</h2><div class=highlight-box><strong>üî¨ Training Protocol:</strong> All methods were trained under identical conditions in Isaacsim with curriculum learning, and domain randomization. Optimization used PPO with GAE over 20k iterations, and each experiment was repeated with 3 seeds.</div><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/sim.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:400;font-size:.85rem;text-align:center;color:#666>Training conducted in IsaacSim with 4096 parallel environments</p><h3 id=baselines>Baselines</h3><ul><li>Hybrid Internal Model: <a href=https://github.com/InternRobotics/HIMLoco target=_blank rel=noopener>HIMLoco</a> .</li><li>Self-learning Latent Representation: <a href=https://github.com/11chens/SLR-master target=_blank rel=noopener>SLR</a>.</li><li>Teacher: Privileged expert policy with full state access (upper bound).</li></ul><h3 id=our-ablations>Our Ablations</h3><ul><li>Ours w/ MLP: Student encoder replaced by a 10-step MLP.</li><li>Ours w/ TCN: Student encoder replaced by a temporal convolutional network.</li><li>Ours w/o Priv: Same architecture but trained without privileged states.</li><li>Ours w/o Priv Vel: No privileged states + no velocity inputs.</li></ul><details><summary style=text-decoration:underline;font-weight:500;font-size:1.05rem;cursor:pointer>üìä Click to Explore Interactive W&B Training Results
 </summary><div style="margin-top:1rem;position:relative;padding-bottom:56.25%;height:650px;overflow:hidden;border-radius:12px;box-shadow:0 4px 20px rgba(0,0,0,.15)"><iframe src=https://api.wandb.ai/links/amrmousa-m/b6z2hs0e style=position:absolute;top:0;left:0;width:100%;height:100%;border:none;border-radius:12px></iframe></div></details><p>Our method achieves:</p><ul><li>‚úÖ Faster convergence than HIM, SLR, and all ablations.</li><li>‚úÖ Higher final returns, surpassing even the privileged Teacher.</li><li>‚úÖ Robust OOD generalization, maintaining strong performance under terrain, friction, and payload shifts.</li></ul><figure id=figure-combined-evaluation-metrics-for-tar-himloco-and-slr-and-ablation-varients><div class="d-flex justify-content-center"><div class=w-100><img alt="Evaluation Results" srcset="/tarloco/images/fig_eval_hu704af59e1f1af352d6b6432f70d0f455_1065332_39e2a59fe0b58c239b517b89bd6c9f26.webp 400w,
/tarloco/images/fig_eval_hu704af59e1f1af352d6b6432f70d0f455_1065332_ff07d1d4f5e62a5994ef3510413f8e5e.webp 760w,
/tarloco/images/fig_eval_hu704af59e1f1af352d6b6432f70d0f455_1065332_1200x1200_fit_q75_h2_lanczos_3.webp 1200w" src=/tarloco/images/fig_eval_hu704af59e1f1af352d6b6432f70d0f455_1065332_39e2a59fe0b58c239b517b89bd6c9f26.webp width=724 height=760 loading=lazy data-zoomable></div></div><figcaption>Combined evaluation metrics for TAR, HIMLoco, and SLR and ablation varients.</figcaption></figure></div><p></br></br></p><script>function showTab(e,t){const n=document.querySelectorAll(".tab-content");n.forEach(e=>e.style.display="none");const s=document.querySelectorAll(".tab-button");s.forEach(e=>e.classList.remove("active")),document.getElementById(e).style.display="block",t.target.classList.add("active")}</script><hr><h2 id=-evaluation>üé¨ Evaluation</h2><div class=highlight-box><strong>üî¨ Evaluation Protocol:</strong> Scenarios include both in-distribution cases (similar to training conditions) and challenging out-of-distribution scenarios that test generalization capabilities.</div><h4 id=in-distribution-testing>In-Distribution Testing</h4><div style=display:flex;justify-content:center;gap:.2rem;margin-top:.2rem><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>Ours</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/id/m0_f0.1_s1.0_7.5k_ours.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.29</p></div><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>HIM</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/id/m0_f0.1_s1.0_7.5k_him.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.32 (<span style=color:red>-10.3%</span>)</div><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>SLR</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/id/m0_f0.1_s1.0_7.5k_slr.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.42 (<span style=color:red>-44.8%</span>)</p></div></div>Model: 7500&nbsp; | &nbsp; Friction Coefficient: 0.1 &nbsp; | &nbsp; Payload: 0 kg &nbsp; | &nbsp; Max Velocity: ¬±1.0 m/s</br></br><h4 id=out-of-distribution-testing>Out-of-Distribution Testing</h4><div style=display:flex;justify-content:center;gap:.2rem;margin-top:.2rem><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>Ours</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/ood/m0_f1.0_s2.0_20k_ours.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.39</p></div><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>HIM</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/ood/m0_f1.0_s2.0_20k_him.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.47 (<span style=color:red>-21%</span>)</div><div style=flex:1;text-align:center><p style=margin:0;font-weight:600>SLR</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.1rem">
<source src=videos/ood/m0_f1.0_s2.0_20k_slr.mp4 type=video/mp4></video><p style=margin-top:-2rem;font-weight:600;font-size:.85rem;color:#666>Error: = 0.63 (<span style=color:red>-64.53%</span>)</p></div></div>Model: 20000 &nbsp; | &nbsp; Friction Coefficient: 1.0 &nbsp; | &nbsp; Payload: 7.5 kg &nbsp; | &nbsp; <span style=color:red>Max Velocity: ¬±2.0 m/s</span><p></br></br></p><h2 id=-real-world-deployment>üêæ Real-World Deployment</h2><p>The videos below showcase TARLoco in action on the Unitree Go2 robot, completely BLIND üßëüèª‚Äçü¶Ø.</p><div style=display:grid;grid-template-columns:repeat(2,1fr);gap:.2rem;margin-top:1rem><div style=grid-column:1/-1;text-align:center><p style=margin:0;font-weight:600>Dense Vegetation</p></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/vegetation2.mp4 type=video/mp4></video></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/vegetation1.mp4 type=video/mp4></video></div><div style=text-align:center><p style=margin:0;font-weight:600>Different Terrains</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/walk.mp4 type=video/mp4></video></div><div style=text-align:center><p style=margin:0;font-weight:600>High-Step Descent</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/steps.mp4 type=video/mp4></video></div><div style=grid-column:1/-1;text-align:center><p style=margin:0;font-weight:600>External Pushes</p></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/pushes1.mp4 type=video/mp4></video></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/pushes2.mp4 type=video/mp4></video></div><div style=text-align:center><p style=margin:0;font-weight:600>Soft Mattress</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/cushions.mp4 type=video/mp4></video></div><div style=text-align:center><p style=margin:0;font-weight:600>10kg Payload</p><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/mass.mp4 type=video/mp4></video></div><div style=grid-column:1/-1;text-align:center><p style=margin:0;font-weight:600>Joint Degradation</p></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/fl_fail.mp4 type=video/mp4></video></div><div style=text-align:center><video controls autoplay muted loop playsinline style="width:100%;border-radius:10px;box-shadow:0 4px 15px rgba(0,0,0,.1);margin-top:.2rem">
<source src=videos/deploy/rr_fail.mp4 type=video/mp4></video></div><div style=grid-column:1/-1;text-align:center;font-size:.85rem;margin-top:-2rem><p style=margin:0;font-weight:500>* Simulating actuator degradation by reducing the joint torque by 90%. Inspired by <a href=https://doi.org/10.1145/3627676.3627686>ADAPT</a>‚Äîbut without custom policy training, we just let the robot figure it out üòé!</p></div><!-- <div style="grid-column: 1 / -1; text-align: center; font-size: 0.85rem; margin-top: -2rem;">
    <p style="margin: 0; font-weight: 500;">* Joint torque was reduced by 90% of its nominal value. This mirrors the <a href="https://doi.org/10.1145/3627676.3627686">ADAPT</a> study in spirit, though without designing a new policy for the impaired setting.</p>
  </div> --></div></br><hr><h2 id=-citation>üìö Citation</h2><p>If you find this work useful, please consider citing our paper:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl><span class=nc>@misc</span><span class=p>{</span><span class=nl>mousa2025tar</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>title</span><span class=p>=</span><span class=s>{TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion}</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>      <span class=na>author</span><span class=p>=</span><span class=s>{Amr Mousa and Neil Karavis and Michele Caprio and Wei Pan and Richard Allmendinger}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>year</span><span class=p>=</span><span class=s>{2025}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>eprint</span><span class=p>=</span><span class=s>{2503.20839}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>archivePrefix</span><span class=p>=</span><span class=s>{arXiv}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>primaryClass</span><span class=p>=</span><span class=s>{cs.RO}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>url</span><span class=p>=</span><span class=s>{https://arxiv.org/abs/2503.20839}</span><span class=p>,</span> 
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><hr><h3 id=-acknowledgments-and-community>üôèüèª Acknowledgments and Community</h3><p>Special thanks to <a href=https://bvadorno.github.io/ target=_blank rel=noopener><strong>Bruno Adorno</strong></a>, <strong>Amy Johnson</strong>, <strong>Darren Cunningham</strong> and <strong>Lesley Pater</strong> from the University of Manchester for providing hardware for testing and their unwavering support.</p><p>This work builds upon <a href=https://github.com/isaac-sim/IsaacLab target=_blank rel=noopener><strong>IsaacLab</strong></a>, <a href=https://github.com/leggedrobotics/rsl_rl target=_blank rel=noopener><strong>RSL-RL</strong></a> and the broader research community. The original licenses apply; new contributions are under <strong>CC BY-NC-SA 4.0</strong>.</p><p>For technical questions and implementation support:</p><ul><li><strong>GitHub Issues:</strong> Report bugs and request features</li><li><strong>Discussions:</strong> Ask questions and share experiences</li><li><strong>Email:</strong> Direct contact for collaboration opportunities</li></ul><div style="text-align:center;margin:2rem 0;padding:2rem;background:linear-gradient(135deg,#f7efcf 0%,#dfc661 100%);color:#fff;border-radius:15px"><h3>üöÄ Ready to Transform Your Quadrupedal Robotics Research?</h3><p style="font-size:1rem;margin:1rem 0;color:#000">Discover how TAR can improve your approach to sim2real transfer and robust locomotion.</p><a href=https://github.com/ammousa/TARLoco style="display:inline-block;background:#fff;color:#91803f;padding:.5rem 2rem;border-radius:25px;text-decoration:none;font-weight:700;margin:.5rem">‚≠ê Star on GitHub</a>
<a href=https://arxiv.org/abs/2503.20839 style="display:inline-block;background:rgba(0,0,0,.2);color:#fff;padding:.5rem 2rem;border-radius:25px;text-decoration:none;font-weight:700;margin:.5rem">üìÑ Read the Paper</a></div></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Famrmousa.com%2Ftarloco%2F&amp;text=" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="https://www.facebook.com/sharer.php?u=https%3A%2F%2Famrmousa.com%2Ftarloco%2F&amp;t=" target=_blank rel=noopener class=share-btn-facebook aria-label=facebook><i class="fab fa-facebook"></i></a></li><li><a href="mailto:?subject=&amp;body=https%3A%2F%2Famrmousa.com%2Ftarloco%2F" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https%3A%2F%2Famrmousa.com%2Ftarloco%2F&amp;title=" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="whatsapp://send?text=%20https%3A%2F%2Famrmousa.com%2Ftarloco%2F" target=_blank rel=noopener class=share-btn-whatsapp aria-label=whatsapp><i class="fab fa-whatsapp"></i></a></li><li><a href="https://service.weibo.com/share/share.php?url=https%3A%2F%2Famrmousa.com%2Ftarloco%2F&amp;title=" target=_blank rel=noopener class=share-btn-weibo aria-label=weibo><i class="fab fa-weibo"></i></a></li></ul></div></div></article></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">¬© 2025 Amr Mousa. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://hugoblox.com/?utm_campaign=poweredby" target=_blank rel=noopener>Hugo Blox Builder</a> ‚Äî the free, <a href=https://github.com/HugoBlox/hugo-blox-builder target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.391d344a129df56f7ad674c2c2ed04e8.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.7f5ebaff62ae468cff8bb3dd1337bb9b.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy
</a><a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.9c0e895144aef5a693008b5c5d450147.js type=module></script></body></html>